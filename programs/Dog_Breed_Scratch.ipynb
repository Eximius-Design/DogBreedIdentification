{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "set_session(tf.Session(config=config))\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dogs=pd.read_csv(\"/home/ramreddyy/Documents/dog_breed/labels.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a1=dogs['breed'].value_counts().index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "def load(inpx,inpy):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for i in range(inpx.shape[0]):\n",
    "        if inpx.iloc[i][1] in a1[:5]:\n",
    "            imgg=image.load_img(\"/home/ramreddyy/Documents/dog_breed/train/\"+inpx.iloc[i][0]+\".jpg\",target_size=(224,224))\n",
    "            arr=image.img_to_array(imgg)\n",
    "            x.append(arr/255)\n",
    "            y.append(inpy.iloc[i])\n",
    "    x=np.asarray(x)\n",
    "    y=np.asarray(y)\n",
    "    one_hot = pd.get_dummies(y, sparse = True)\n",
    "    one_hot_labels = np.asarray(one_hot)\n",
    "    return x,one_hot_labels\n",
    "    \n",
    "a,y=load(inpx=dogs,inpy=dogs.breed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "for train_index, test_index in sss.split(a,y):\n",
    "    x_train, x_test = a[train_index], a[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "def createModel():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(224,224,3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(8, 8)))\n",
    "    model.add(Dropout(0.1))\n",
    " \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "    model.add(Dropout(0.1))\n",
    " \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8/8 [==============================] - 3s 416ms/step - loss: 1.6230 - acc: 0.1894 - val_loss: 1.6083 - val_acc: 0.2034\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 3s 345ms/step - loss: 1.6099 - acc: 0.1960 - val_loss: 1.6071 - val_acc: 0.1949\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 3s 365ms/step - loss: 1.6079 - acc: 0.2079 - val_loss: 1.6054 - val_acc: 0.2119\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 3s 359ms/step - loss: 1.6116 - acc: 0.2428 - val_loss: 1.6048 - val_acc: 0.2119\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 3s 350ms/step - loss: 1.6079 - acc: 0.2211 - val_loss: 1.6041 - val_acc: 0.2373\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 3s 357ms/step - loss: 1.6016 - acc: 0.2922 - val_loss: 1.5772 - val_acc: 0.3644\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 3s 375ms/step - loss: 1.5850 - acc: 0.2652 - val_loss: 1.5906 - val_acc: 0.2203\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 3s 373ms/step - loss: 1.5402 - acc: 0.2968 - val_loss: 1.4668 - val_acc: 0.3644\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 3s 356ms/step - loss: 1.4568 - acc: 0.3263 - val_loss: 1.6943 - val_acc: 0.2542\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 3s 353ms/step - loss: 1.4614 - acc: 0.3368 - val_loss: 1.3906 - val_acc: 0.3475\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 3s 418ms/step - loss: 1.3918 - acc: 0.3612 - val_loss: 1.3020 - val_acc: 0.4153\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 3s 371ms/step - loss: 1.4298 - acc: 0.3848 - val_loss: 1.4986 - val_acc: 0.2712\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 3s 358ms/step - loss: 1.3786 - acc: 0.3996 - val_loss: 1.4098 - val_acc: 0.3305\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 3s 374ms/step - loss: 1.3206 - acc: 0.4322 - val_loss: 1.2400 - val_acc: 0.4322\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 3s 360ms/step - loss: 1.2467 - acc: 0.4961 - val_loss: 1.2436 - val_acc: 0.4576\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 3s 367ms/step - loss: 1.2979 - acc: 0.4474 - val_loss: 1.1736 - val_acc: 0.4661\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 3s 404ms/step - loss: 1.2706 - acc: 0.4493 - val_loss: 1.1753 - val_acc: 0.4831\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 3s 354ms/step - loss: 1.2067 - acc: 0.4922 - val_loss: 1.1141 - val_acc: 0.5254\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 3s 376ms/step - loss: 1.1912 - acc: 0.5046 - val_loss: 1.1084 - val_acc: 0.4831\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 3s 380ms/step - loss: 1.1838 - acc: 0.4731 - val_loss: 1.2516 - val_acc: 0.4492\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 3s 383ms/step - loss: 1.2157 - acc: 0.4890 - val_loss: 1.1506 - val_acc: 0.4746\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 3s 356ms/step - loss: 1.0870 - acc: 0.5737 - val_loss: 1.2426 - val_acc: 0.4576\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 3s 358ms/step - loss: 1.1306 - acc: 0.5250 - val_loss: 1.3618 - val_acc: 0.3475\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 3s 373ms/step - loss: 1.1219 - acc: 0.5275 - val_loss: 1.1129 - val_acc: 0.5000\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 3s 380ms/step - loss: 1.0505 - acc: 0.5527 - val_loss: 1.1383 - val_acc: 0.4831\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 3s 353ms/step - loss: 1.0920 - acc: 0.5507 - val_loss: 1.1883 - val_acc: 0.4831\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 3s 356ms/step - loss: 1.1047 - acc: 0.5461 - val_loss: 1.1037 - val_acc: 0.4407\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 3s 340ms/step - loss: 1.0154 - acc: 0.5566 - val_loss: 1.1314 - val_acc: 0.4492\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 3s 358ms/step - loss: 1.0323 - acc: 0.5776 - val_loss: 1.1383 - val_acc: 0.4746\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 3s 362ms/step - loss: 0.9376 - acc: 0.6092 - val_loss: 1.1626 - val_acc: 0.5593\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 3s 360ms/step - loss: 0.9609 - acc: 0.5948 - val_loss: 1.3226 - val_acc: 0.4746\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 3s 365ms/step - loss: 1.0174 - acc: 0.5519 - val_loss: 1.3895 - val_acc: 0.3729\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 3s 350ms/step - loss: 0.9885 - acc: 0.5862 - val_loss: 1.3472 - val_acc: 0.4492\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 3s 351ms/step - loss: 0.9488 - acc: 0.5855 - val_loss: 1.3067 - val_acc: 0.4831\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 3s 369ms/step - loss: 0.9188 - acc: 0.6113 - val_loss: 1.2109 - val_acc: 0.5339\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 3s 363ms/step - loss: 0.9184 - acc: 0.6027 - val_loss: 1.1264 - val_acc: 0.4915\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 3s 354ms/step - loss: 0.8938 - acc: 0.6546 - val_loss: 1.1591 - val_acc: 0.5085\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 3s 346ms/step - loss: 0.8797 - acc: 0.6204 - val_loss: 1.2268 - val_acc: 0.4746\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 3s 355ms/step - loss: 0.8692 - acc: 0.6553 - val_loss: 1.2510 - val_acc: 0.5339\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 3s 358ms/step - loss: 0.8782 - acc: 0.6277 - val_loss: 1.1210 - val_acc: 0.5169\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 3s 367ms/step - loss: 0.9397 - acc: 0.6177 - val_loss: 0.9972 - val_acc: 0.5424\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 3s 354ms/step - loss: 0.8291 - acc: 0.6573 - val_loss: 1.0174 - val_acc: 0.5508\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 3s 358ms/step - loss: 0.8606 - acc: 0.6467 - val_loss: 1.1313 - val_acc: 0.5847\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 3s 364ms/step - loss: 0.8037 - acc: 0.6506 - val_loss: 1.2608 - val_acc: 0.5593\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 3s 375ms/step - loss: 0.9222 - acc: 0.6198 - val_loss: 1.5387 - val_acc: 0.3814\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 3s 362ms/step - loss: 0.8455 - acc: 0.6152 - val_loss: 1.1768 - val_acc: 0.5169\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 3s 397ms/step - loss: 0.8674 - acc: 0.6257 - val_loss: 1.1702 - val_acc: 0.4746\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 3s 360ms/step - loss: 0.7796 - acc: 0.6598 - val_loss: 1.1595 - val_acc: 0.5424\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 3s 353ms/step - loss: 0.7345 - acc: 0.7217 - val_loss: 1.2488 - val_acc: 0.5508\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 3s 366ms/step - loss: 0.6964 - acc: 0.6946 - val_loss: 1.2435 - val_acc: 0.5339\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 3s 388ms/step - loss: 0.8162 - acc: 0.6756 - val_loss: 1.2538 - val_acc: 0.4661\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 3s 363ms/step - loss: 0.8140 - acc: 0.6809 - val_loss: 1.2290 - val_acc: 0.5508\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 3s 358ms/step - loss: 0.7704 - acc: 0.6671 - val_loss: 1.2279 - val_acc: 0.5339\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 3s 340ms/step - loss: 0.7183 - acc: 0.7402 - val_loss: 1.3712 - val_acc: 0.5000\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 3s 372ms/step - loss: 0.7092 - acc: 0.7297 - val_loss: 1.2054 - val_acc: 0.5424\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 3s 368ms/step - loss: 0.7465 - acc: 0.6888 - val_loss: 1.1168 - val_acc: 0.5339\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 3s 359ms/step - loss: 0.6765 - acc: 0.7086 - val_loss: 1.1980 - val_acc: 0.5339\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 3s 377ms/step - loss: 0.7055 - acc: 0.6750 - val_loss: 1.0906 - val_acc: 0.5508\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 3s 372ms/step - loss: 0.6728 - acc: 0.7190 - val_loss: 1.1544 - val_acc: 0.5424\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 3s 355ms/step - loss: 0.6139 - acc: 0.7368 - val_loss: 1.1218 - val_acc: 0.6102\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 3s 375ms/step - loss: 0.6455 - acc: 0.7389 - val_loss: 1.3050 - val_acc: 0.5763\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 3s 371ms/step - loss: 0.6686 - acc: 0.6999 - val_loss: 1.2612 - val_acc: 0.5339\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 3s 358ms/step - loss: 0.6177 - acc: 0.7178 - val_loss: 1.1806 - val_acc: 0.5678\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 3s 374ms/step - loss: 0.6558 - acc: 0.7224 - val_loss: 1.0393 - val_acc: 0.5932\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 3s 356ms/step - loss: 0.6234 - acc: 0.7619 - val_loss: 1.0463 - val_acc: 0.5847\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 3s 354ms/step - loss: 0.6354 - acc: 0.7487 - val_loss: 1.2407 - val_acc: 0.5593\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 3s 355ms/step - loss: 0.6374 - acc: 0.7269 - val_loss: 1.1355 - val_acc: 0.5932\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 3s 362ms/step - loss: 0.6139 - acc: 0.7586 - val_loss: 1.2000 - val_acc: 0.5424\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 3s 361ms/step - loss: 0.5759 - acc: 0.7467 - val_loss: 1.1519 - val_acc: 0.5932\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 3s 398ms/step - loss: 0.6558 - acc: 0.7362 - val_loss: 1.0833 - val_acc: 0.6186\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 3s 344ms/step - loss: 0.5917 - acc: 0.7631 - val_loss: 1.1177 - val_acc: 0.5763\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 3s 371ms/step - loss: 0.5125 - acc: 0.7928 - val_loss: 1.2496 - val_acc: 0.6271\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 3s 369ms/step - loss: 0.5362 - acc: 0.7894 - val_loss: 1.4155 - val_acc: 0.5508\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 3s 358ms/step - loss: 0.5966 - acc: 0.7704 - val_loss: 1.3630 - val_acc: 0.5169\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 3s 345ms/step - loss: 0.5896 - acc: 0.7611 - val_loss: 1.2330 - val_acc: 0.6186\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 3s 334ms/step - loss: 0.5374 - acc: 0.7697 - val_loss: 1.2113 - val_acc: 0.5254\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 3s 343ms/step - loss: 0.5308 - acc: 0.7822 - val_loss: 1.4736 - val_acc: 0.5424\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 3s 347ms/step - loss: 0.5689 - acc: 0.7526 - val_loss: 1.2827 - val_acc: 0.5593\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 3s 342ms/step - loss: 0.5377 - acc: 0.7822 - val_loss: 1.2464 - val_acc: 0.6102\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 3s 360ms/step - loss: 0.4773 - acc: 0.8198 - val_loss: 1.2421 - val_acc: 0.5932\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 3s 362ms/step - loss: 0.5055 - acc: 0.7881 - val_loss: 1.1834 - val_acc: 0.6102\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 3s 362ms/step - loss: 0.4766 - acc: 0.8020 - val_loss: 1.1011 - val_acc: 0.6186\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 3s 343ms/step - loss: 0.4520 - acc: 0.8152 - val_loss: 1.3707 - val_acc: 0.5763\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 3s 383ms/step - loss: 0.4652 - acc: 0.8106 - val_loss: 1.2804 - val_acc: 0.5932\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 3s 359ms/step - loss: 0.4371 - acc: 0.8237 - val_loss: 1.4343 - val_acc: 0.5932\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 3s 348ms/step - loss: 0.5003 - acc: 0.8250 - val_loss: 1.2185 - val_acc: 0.6186\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 3s 354ms/step - loss: 0.4767 - acc: 0.8054 - val_loss: 1.2360 - val_acc: 0.5678\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 3s 343ms/step - loss: 0.4645 - acc: 0.8250 - val_loss: 1.2387 - val_acc: 0.5932\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 3s 353ms/step - loss: 0.4879 - acc: 0.7935 - val_loss: 1.2474 - val_acc: 0.6102\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 3s 375ms/step - loss: 0.4852 - acc: 0.8033 - val_loss: 1.1678 - val_acc: 0.6525\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 3s 333ms/step - loss: 0.4737 - acc: 0.8184 - val_loss: 1.2062 - val_acc: 0.5763\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 3s 357ms/step - loss: 0.4253 - acc: 0.8237 - val_loss: 0.8737 - val_acc: 0.6610\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 3s 369ms/step - loss: 0.4715 - acc: 0.8013 - val_loss: 0.9773 - val_acc: 0.6864\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 3s 346ms/step - loss: 0.5051 - acc: 0.7769 - val_loss: 1.0568 - val_acc: 0.6271\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 3s 346ms/step - loss: 0.4054 - acc: 0.8264 - val_loss: 1.1934 - val_acc: 0.6525\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 3s 366ms/step - loss: 0.4852 - acc: 0.7974 - val_loss: 1.3335 - val_acc: 0.5763\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 3s 375ms/step - loss: 0.4650 - acc: 0.7966 - val_loss: 1.2369 - val_acc: 0.6102\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 3s 353ms/step - loss: 0.4685 - acc: 0.8139 - val_loss: 1.1466 - val_acc: 0.5932\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 3s 347ms/step - loss: 0.4663 - acc: 0.8165 - val_loss: 1.3242 - val_acc: 0.5932\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 3s 358ms/step - loss: 0.4347 - acc: 0.8264 - val_loss: 1.2830 - val_acc: 0.5932\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 3s 375ms/step - loss: 0.3956 - acc: 0.8336 - val_loss: 1.3161 - val_acc: 0.6017\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 3s 348ms/step - loss: 0.3540 - acc: 0.8586 - val_loss: 1.1910 - val_acc: 0.6102\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 3s 348ms/step - loss: 0.3699 - acc: 0.8500 - val_loss: 1.3673 - val_acc: 0.6356\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 3s 355ms/step - loss: 0.3280 - acc: 0.8626 - val_loss: 1.6342 - val_acc: 0.5932\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 3s 347ms/step - loss: 0.3173 - acc: 0.8652 - val_loss: 1.5141 - val_acc: 0.6102\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 3s 360ms/step - loss: 0.3574 - acc: 0.8632 - val_loss: 1.3183 - val_acc: 0.6864\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 3s 344ms/step - loss: 0.3535 - acc: 0.8658 - val_loss: 1.1012 - val_acc: 0.6780\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 3s 336ms/step - loss: 0.3726 - acc: 0.8453 - val_loss: 1.1439 - val_acc: 0.6864\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 3s 345ms/step - loss: 0.3641 - acc: 0.8573 - val_loss: 1.4508 - val_acc: 0.6102\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 3s 343ms/step - loss: 0.4062 - acc: 0.8559 - val_loss: 1.2530 - val_acc: 0.5932\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 3s 362ms/step - loss: 0.3581 - acc: 0.8659 - val_loss: 1.0956 - val_acc: 0.6525\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 3s 435ms/step - loss: 0.3731 - acc: 0.8520 - val_loss: 1.1321 - val_acc: 0.7034\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 3s 340ms/step - loss: 0.3860 - acc: 0.8526 - val_loss: 1.5208 - val_acc: 0.6356\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 3s 339ms/step - loss: 0.4145 - acc: 0.8493 - val_loss: 1.4832 - val_acc: 0.5678\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 3s 353ms/step - loss: 0.4153 - acc: 0.8618 - val_loss: 1.4714 - val_acc: 0.5763\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 3s 353ms/step - loss: 0.3775 - acc: 0.8586 - val_loss: 1.1477 - val_acc: 0.6525\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 3s 365ms/step - loss: 0.3997 - acc: 0.8375 - val_loss: 1.2767 - val_acc: 0.6780\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 3s 347ms/step - loss: 0.3104 - acc: 0.8750 - val_loss: 1.2219 - val_acc: 0.6441\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 3s 370ms/step - loss: 0.3293 - acc: 0.8697 - val_loss: 1.0724 - val_acc: 0.7119\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 3s 358ms/step - loss: 0.2890 - acc: 0.8882 - val_loss: 1.4006 - val_acc: 0.6949\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 3s 344ms/step - loss: 0.2905 - acc: 0.8941 - val_loss: 1.4316 - val_acc: 0.6780\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 3s 358ms/step - loss: 0.3009 - acc: 0.8809 - val_loss: 1.4048 - val_acc: 0.6271\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 3s 365ms/step - loss: 0.2816 - acc: 0.8809 - val_loss: 1.5993 - val_acc: 0.5763\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 3s 362ms/step - loss: 0.2863 - acc: 0.8763 - val_loss: 1.3058 - val_acc: 0.6695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200\n",
      "8/8 [==============================] - 3s 357ms/step - loss: 0.2544 - acc: 0.9053 - val_loss: 1.3990 - val_acc: 0.6186\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 3s 362ms/step - loss: 0.2801 - acc: 0.8829 - val_loss: 1.2634 - val_acc: 0.6525\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 3s 350ms/step - loss: 0.3264 - acc: 0.8869 - val_loss: 1.4377 - val_acc: 0.5847\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 3s 405ms/step - loss: 0.2726 - acc: 0.8882 - val_loss: 1.5806 - val_acc: 0.5763\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 3s 410ms/step - loss: 0.2618 - acc: 0.9119 - val_loss: 1.3785 - val_acc: 0.6441\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 3s 370ms/step - loss: 0.3228 - acc: 0.8823 - val_loss: 1.2101 - val_acc: 0.6441\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 3s 360ms/step - loss: 0.3097 - acc: 0.8843 - val_loss: 1.0616 - val_acc: 0.7203\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 3s 362ms/step - loss: 0.2369 - acc: 0.9000 - val_loss: 1.2415 - val_acc: 0.6356\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 3s 389ms/step - loss: 0.3134 - acc: 0.8934 - val_loss: 1.7188 - val_acc: 0.5932\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 3s 374ms/step - loss: 0.2948 - acc: 0.8783 - val_loss: 1.8216 - val_acc: 0.5763\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 3s 360ms/step - loss: 0.3731 - acc: 0.8513 - val_loss: 1.6900 - val_acc: 0.6017\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 3s 370ms/step - loss: 0.3516 - acc: 0.8598 - val_loss: 1.6459 - val_acc: 0.5508\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 3s 349ms/step - loss: 0.3501 - acc: 0.8580 - val_loss: 1.2194 - val_acc: 0.6864\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 3s 353ms/step - loss: 0.4037 - acc: 0.8322 - val_loss: 1.0360 - val_acc: 0.6525\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 3s 342ms/step - loss: 0.2728 - acc: 0.8980 - val_loss: 1.0873 - val_acc: 0.6949\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 3s 349ms/step - loss: 0.2654 - acc: 0.8934 - val_loss: 1.1275 - val_acc: 0.6864\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 3s 378ms/step - loss: 0.1950 - acc: 0.9316 - val_loss: 1.6697 - val_acc: 0.6186\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 3s 361ms/step - loss: 0.2551 - acc: 0.8961 - val_loss: 1.4770 - val_acc: 0.6102\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 3s 349ms/step - loss: 0.2437 - acc: 0.9066 - val_loss: 1.4545 - val_acc: 0.6610\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 3s 361ms/step - loss: 0.2289 - acc: 0.9145 - val_loss: 1.4969 - val_acc: 0.6610\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 3s 376ms/step - loss: 0.2469 - acc: 0.9020 - val_loss: 1.4457 - val_acc: 0.6695\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 3s 362ms/step - loss: 0.2423 - acc: 0.9138 - val_loss: 1.6063 - val_acc: 0.6186\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 3s 353ms/step - loss: 0.2338 - acc: 0.9105 - val_loss: 1.5819 - val_acc: 0.6356\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 3s 367ms/step - loss: 0.1961 - acc: 0.9190 - val_loss: 1.6319 - val_acc: 0.6610\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 3s 368ms/step - loss: 0.2773 - acc: 0.8921 - val_loss: 1.2198 - val_acc: 0.6864\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 3s 360ms/step - loss: 0.2388 - acc: 0.9231 - val_loss: 1.1285 - val_acc: 0.7034\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 3s 362ms/step - loss: 0.2511 - acc: 0.9020 - val_loss: 1.5239 - val_acc: 0.5932\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 3s 349ms/step - loss: 0.2698 - acc: 0.9059 - val_loss: 1.9182 - val_acc: 0.5763\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 3s 361ms/step - loss: 0.3433 - acc: 0.8611 - val_loss: 1.4462 - val_acc: 0.6356\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 3s 351ms/step - loss: 0.3243 - acc: 0.8842 - val_loss: 1.2841 - val_acc: 0.7119\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 3s 351ms/step - loss: 0.2603 - acc: 0.9020 - val_loss: 1.0737 - val_acc: 0.7203\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 3s 422ms/step - loss: 0.2365 - acc: 0.9079 - val_loss: 1.5989 - val_acc: 0.6271\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 3s 374ms/step - loss: 0.2551 - acc: 0.9092 - val_loss: 1.2494 - val_acc: 0.6695\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 3s 389ms/step - loss: 0.3104 - acc: 0.8966 - val_loss: 1.3792 - val_acc: 0.6102\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 3s 385ms/step - loss: 0.2607 - acc: 0.9000 - val_loss: 1.2178 - val_acc: 0.6780\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 3s 353ms/step - loss: 0.2285 - acc: 0.9052 - val_loss: 1.3469 - val_acc: 0.6780\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 3s 343ms/step - loss: 0.2033 - acc: 0.9296 - val_loss: 1.4282 - val_acc: 0.6864\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 3s 357ms/step - loss: 0.1792 - acc: 0.9349 - val_loss: 1.6473 - val_acc: 0.6271\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 3s 374ms/step - loss: 0.2419 - acc: 0.9065 - val_loss: 1.6687 - val_acc: 0.6695\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 3s 379ms/step - loss: 0.2657 - acc: 0.9079 - val_loss: 0.9470 - val_acc: 0.7034\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 3s 360ms/step - loss: 0.2462 - acc: 0.9125 - val_loss: 1.1326 - val_acc: 0.6949\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 3s 356ms/step - loss: 0.2122 - acc: 0.9257 - val_loss: 1.6735 - val_acc: 0.6780\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 3s 336ms/step - loss: 0.2436 - acc: 0.9119 - val_loss: 1.3934 - val_acc: 0.6780\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 3s 364ms/step - loss: 0.2908 - acc: 0.8994 - val_loss: 1.5949 - val_acc: 0.5932\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 3s 396ms/step - loss: 0.2919 - acc: 0.8868 - val_loss: 1.8790 - val_acc: 0.5763\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 3s 354ms/step - loss: 0.3748 - acc: 0.8645 - val_loss: 1.1032 - val_acc: 0.7034\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 3s 350ms/step - loss: 0.2766 - acc: 0.9164 - val_loss: 1.1711 - val_acc: 0.6864\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 3s 356ms/step - loss: 0.2389 - acc: 0.9138 - val_loss: 1.1177 - val_acc: 0.6864\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 3s 325ms/step - loss: 0.2419 - acc: 0.9086 - val_loss: 1.2611 - val_acc: 0.6695\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 3s 360ms/step - loss: 0.1945 - acc: 0.9263 - val_loss: 1.3548 - val_acc: 0.6864\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 3s 382ms/step - loss: 0.1737 - acc: 0.9310 - val_loss: 1.3020 - val_acc: 0.6525\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 3s 350ms/step - loss: 0.1713 - acc: 0.9349 - val_loss: 1.4366 - val_acc: 0.6780\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 3s 354ms/step - loss: 0.1989 - acc: 0.9263 - val_loss: 1.4908 - val_acc: 0.6356\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 3s 344ms/step - loss: 0.2305 - acc: 0.9250 - val_loss: 1.2722 - val_acc: 0.7288\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 3s 350ms/step - loss: 0.1368 - acc: 0.9586 - val_loss: 1.4314 - val_acc: 0.6695\n",
      "Epoch 180/200\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.0556 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "model2 = createModel()\n",
    " \n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "save=keras.callbacks.ModelCheckpoint('/home/ramreddyy/model_save', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "tensor=keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=16, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "datagen = ImageDataGenerator(\n",
    "                            zoom_range=0.2,\n",
    "                            rotation_range=30,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            horizontal_flip=True,\n",
    "                            vertical_flip=False) \n",
    "\n",
    "history2 = model2.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                              steps_per_epoch=int(np.ceil(x_train.shape[0] / float(batch_size))),\n",
    "                              epochs=epochs,\n",
    "                              validation_data=(x_test, y_test),\n",
    "                              workers=4,\n",
    "                               callbacks=[save,tensor])\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history2.history['loss'],'r',linewidth=3.0)\n",
    "plt.plot(history2.history['val_loss'],'b',linewidth=3.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss Curves',fontsize=16)\n",
    "\n",
    "\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history2.history['acc'],'r',linewidth=3.0)\n",
    "plt.plot(history2.history['val_acc'],'b',linewidth=3.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
