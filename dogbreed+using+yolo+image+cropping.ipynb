{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "set_session(tf.Session(config=config))\n",
    "#import keras\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from matplotlib.pyplot import imshow\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input,Dense, Dropout, Flatten,Activation, Conv2D, MaxPooling2D,BatchNormalization,GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "keras.backend.set_image_data_format(\"channels_last\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1:\n",
    "a)creating a train generator-This train generator is attached with 120 classes each class represent a dog breed.\n",
    " this 120 floders consist of cropped images using yolo(you only look once).\n",
    "\n",
    "b)similarly creating a validation generator with 1200 samples with 10 cropped dog samples for each class \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10672 images belonging to 120 classes.\n",
      "Found 1200 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=0.2  ,horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/home/sainathb/Image_Classification/demo1/',\n",
    "        target_size=(224,224),\n",
    "        batch_size=60,class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '/home/share/dog_val/',\n",
    "        target_size=(224,224),\n",
    "        batch_size=60,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2:\n",
    "importing Xception pre-trained model from keras with imagenet weights and freezing the convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model=keras.applications.xception.Xception(include_top=False, weights='imagenet',input_shape=(224,224,3),pooling='avg')\n",
    "base_model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_6 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)            (None, 111, 111, 32)  864         input_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormalizat (None, 111, 111, 32)  128         block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)    (None, 111, 111, 32)  0           block1_conv1_bn[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)            (None, 109, 109, 64)  18432       block1_conv1_act[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormalizat (None, 109, 109, 64)  256         block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)    (None, 109, 109, 64)  0           block1_conv2_bn[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2D (None, 109, 109, 128) 8768        block1_conv2_act[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormali (None, 109, 109, 128) 512         block2_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation) (None, 109, 109, 128) 0           block2_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2D (None, 109, 109, 128) 17536       block2_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormali (None, 109, 109, 128) 512         block2_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, 55, 55, 128)   8192        block1_conv2_act[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 55, 55, 128)   0           block2_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNor (None, 55, 55, 128)   512         conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_61 (Add)                     (None, 55, 55, 128)   0           block2_pool[0][0]                \n",
      "                                                                   batch_normalization_28[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation) (None, 55, 55, 128)   0           add_61[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2D (None, 55, 55, 256)   33920       block3_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormali (None, 55, 55, 256)   1024        block3_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation) (None, 55, 55, 256)   0           block3_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2D (None, 55, 55, 256)   67840       block3_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormali (None, 55, 55, 256)   1024        block3_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, 28, 28, 256)   32768       add_61[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 28, 28, 256)   0           block3_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNor (None, 28, 28, 256)   1024        conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_62 (Add)                     (None, 28, 28, 256)   0           block3_pool[0][0]                \n",
      "                                                                   batch_normalization_29[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation) (None, 28, 28, 256)   0           add_62[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2D (None, 28, 28, 728)   188672      block4_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormali (None, 28, 28, 728)   2912        block4_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation) (None, 28, 28, 728)   0           block4_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2D (None, 28, 28, 728)   536536      block4_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormali (None, 28, 28, 728)   2912        block4_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, 14, 14, 728)   186368      add_62[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 14, 14, 728)   0           block4_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNor (None, 14, 14, 728)   2912        conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_63 (Add)                     (None, 14, 14, 728)   0           block4_pool[0][0]                \n",
      "                                                                   batch_normalization_30[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation) (None, 14, 14, 728)   0           add_63[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2D (None, 14, 14, 728)   536536      block5_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormali (None, 14, 14, 728)   2912        block5_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation) (None, 14, 14, 728)   0           block5_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2D (None, 14, 14, 728)   536536      block5_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormali (None, 14, 14, 728)   2912        block5_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation) (None, 14, 14, 728)   0           block5_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2D (None, 14, 14, 728)   536536      block5_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormali (None, 14, 14, 728)   2912        block5_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_64 (Add)                     (None, 14, 14, 728)   0           block5_sepconv3_bn[0][0]         \n",
      "                                                                   add_63[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation) (None, 14, 14, 728)   0           add_64[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2D (None, 14, 14, 728)   536536      block6_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormali (None, 14, 14, 728)   2912        block6_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation) (None, 14, 14, 728)   0           block6_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2D (None, 14, 14, 728)   536536      block6_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormali (None, 14, 14, 728)   2912        block6_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation) (None, 14, 14, 728)   0           block6_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2D (None, 14, 14, 728)   536536      block6_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormali (None, 14, 14, 728)   2912        block6_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_65 (Add)                     (None, 14, 14, 728)   0           block6_sepconv3_bn[0][0]         \n",
      "                                                                   add_64[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation) (None, 14, 14, 728)   0           add_65[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2D (None, 14, 14, 728)   536536      block7_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormali (None, 14, 14, 728)   2912        block7_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation) (None, 14, 14, 728)   0           block7_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2D (None, 14, 14, 728)   536536      block7_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormali (None, 14, 14, 728)   2912        block7_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation) (None, 14, 14, 728)   0           block7_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2D (None, 14, 14, 728)   536536      block7_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormali (None, 14, 14, 728)   2912        block7_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_66 (Add)                     (None, 14, 14, 728)   0           block7_sepconv3_bn[0][0]         \n",
      "                                                                   add_65[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation) (None, 14, 14, 728)   0           add_66[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2D (None, 14, 14, 728)   536536      block8_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormali (None, 14, 14, 728)   2912        block8_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation) (None, 14, 14, 728)   0           block8_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2D (None, 14, 14, 728)   536536      block8_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormali (None, 14, 14, 728)   2912        block8_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation) (None, 14, 14, 728)   0           block8_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2D (None, 14, 14, 728)   536536      block8_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormali (None, 14, 14, 728)   2912        block8_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_67 (Add)                     (None, 14, 14, 728)   0           block8_sepconv3_bn[0][0]         \n",
      "                                                                   add_66[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation) (None, 14, 14, 728)   0           add_67[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2D (None, 14, 14, 728)   536536      block9_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormali (None, 14, 14, 728)   2912        block9_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation) (None, 14, 14, 728)   0           block9_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2D (None, 14, 14, 728)   536536      block9_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormali (None, 14, 14, 728)   2912        block9_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation) (None, 14, 14, 728)   0           block9_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2D (None, 14, 14, 728)   536536      block9_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormali (None, 14, 14, 728)   2912        block9_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_68 (Add)                     (None, 14, 14, 728)   0           block9_sepconv3_bn[0][0]         \n",
      "                                                                   add_67[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activation (None, 14, 14, 728)   0           add_68[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv2 (None, 14, 14, 728)   536536      block10_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNormal (None, 14, 14, 728)   2912        block10_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activation (None, 14, 14, 728)   0           block10_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv2 (None, 14, 14, 728)   536536      block10_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNormal (None, 14, 14, 728)   2912        block10_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activation (None, 14, 14, 728)   0           block10_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv2 (None, 14, 14, 728)   536536      block10_sepconv3_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNormal (None, 14, 14, 728)   2912        block10_sepconv3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_69 (Add)                     (None, 14, 14, 728)   0           block10_sepconv3_bn[0][0]        \n",
      "                                                                   add_68[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activation (None, 14, 14, 728)   0           add_69[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv2 (None, 14, 14, 728)   536536      block11_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNormal (None, 14, 14, 728)   2912        block11_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activation (None, 14, 14, 728)   0           block11_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv2 (None, 14, 14, 728)   536536      block11_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNormal (None, 14, 14, 728)   2912        block11_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activation (None, 14, 14, 728)   0           block11_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv2 (None, 14, 14, 728)   536536      block11_sepconv3_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNormal (None, 14, 14, 728)   2912        block11_sepconv3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_70 (Add)                     (None, 14, 14, 728)   0           block11_sepconv3_bn[0][0]        \n",
      "                                                                   add_69[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activation (None, 14, 14, 728)   0           add_70[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv2 (None, 14, 14, 728)   536536      block12_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNormal (None, 14, 14, 728)   2912        block12_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activation (None, 14, 14, 728)   0           block12_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv2 (None, 14, 14, 728)   536536      block12_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNormal (None, 14, 14, 728)   2912        block12_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activation (None, 14, 14, 728)   0           block12_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv2 (None, 14, 14, 728)   536536      block12_sepconv3_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNormal (None, 14, 14, 728)   2912        block12_sepconv3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_71 (Add)                     (None, 14, 14, 728)   0           block12_sepconv3_bn[0][0]        \n",
      "                                                                   add_70[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activation (None, 14, 14, 728)   0           add_71[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv2 (None, 14, 14, 728)   536536      block13_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNormal (None, 14, 14, 728)   2912        block13_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activation (None, 14, 14, 728)   0           block13_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv2 (None, 14, 14, 1024)  752024      block13_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNormal (None, 14, 14, 1024)  4096        block13_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, 7, 7, 1024)    745472      add_71[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)      (None, 7, 7, 1024)    0           block13_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNor (None, 7, 7, 1024)    4096        conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_72 (Add)                     (None, 7, 7, 1024)    0           block13_pool[0][0]               \n",
      "                                                                   batch_normalization_31[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv2 (None, 7, 7, 1536)    1582080     add_72[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNormal (None, 7, 7, 1536)    6144        block14_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activation (None, 7, 7, 1536)    0           block14_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv2 (None, 7, 7, 2048)    3159552     block14_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNormal (None, 7, 7, 2048)    8192        block14_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activation (None, 7, 7, 2048)    0           block14_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glob (None, 2048)          0           block14_sepconv2_act[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 0\n",
      "Non-trainable params: 20,861,480\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3:\n",
    "Connecting Xception model to dense networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 2048)              20861480  \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 120)               123000    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 120)               0         \n",
      "=================================================================\n",
      "Total params: 23,086,752\n",
      "Trainable params: 2,223,224\n",
      "Non-trainable params: 20,863,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(120))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4:\n",
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "200/200 [==============================] - 180s - loss: 1.8184 - acc: 0.5598 - val_loss: 0.8055 - val_acc: 0.8117\n",
      "Epoch 2/75\n",
      "200/200 [==============================] - 195s - loss: 1.6305 - acc: 0.5955 - val_loss: 0.8877 - val_acc: 0.8017\n",
      "Epoch 3/75\n",
      "200/200 [==============================] - 221s - loss: 1.4772 - acc: 0.6247 - val_loss: 0.7711 - val_acc: 0.8158\n",
      "Epoch 4/75\n",
      "200/200 [==============================] - 220s - loss: 1.3921 - acc: 0.6382 - val_loss: 0.8173 - val_acc: 0.8125\n",
      "Epoch 5/75\n",
      "200/200 [==============================] - 221s - loss: 1.3181 - acc: 0.6552 - val_loss: 0.7566 - val_acc: 0.8233\n",
      "Epoch 6/75\n",
      "200/200 [==============================] - 221s - loss: 1.2507 - acc: 0.6764 - val_loss: 0.7829 - val_acc: 0.8158\n",
      "Epoch 7/75\n",
      "200/200 [==============================] - 220s - loss: 1.1877 - acc: 0.6904 - val_loss: 0.7643 - val_acc: 0.8242\n",
      "Epoch 8/75\n",
      "200/200 [==============================] - 221s - loss: 1.1343 - acc: 0.6986 - val_loss: 0.7616 - val_acc: 0.8175\n",
      "Epoch 9/75\n",
      "200/200 [==============================] - 221s - loss: 1.0832 - acc: 0.7194 - val_loss: 0.8105 - val_acc: 0.8208\n",
      "Epoch 10/75\n",
      "200/200 [==============================] - 221s - loss: 1.0350 - acc: 0.7294 - val_loss: 0.7674 - val_acc: 0.8233\n",
      "Epoch 11/75\n",
      "200/200 [==============================] - 222s - loss: 1.0128 - acc: 0.7319 - val_loss: 0.7521 - val_acc: 0.8342\n",
      "Epoch 12/75\n",
      "200/200 [==============================] - 221s - loss: 0.9701 - acc: 0.7446 - val_loss: 0.7882 - val_acc: 0.8200\n",
      "Epoch 13/75\n",
      "200/200 [==============================] - 220s - loss: 0.9301 - acc: 0.7555 - val_loss: 0.7992 - val_acc: 0.8317\n",
      "Epoch 14/75\n",
      "200/200 [==============================] - 221s - loss: 0.9109 - acc: 0.7617 - val_loss: 0.6928 - val_acc: 0.8225\n",
      "Epoch 15/75\n",
      "200/200 [==============================] - 220s - loss: 0.8779 - acc: 0.7739 - val_loss: 0.7539 - val_acc: 0.8317\n",
      "Epoch 16/75\n",
      "200/200 [==============================] - 220s - loss: 0.8627 - acc: 0.7728 - val_loss: 0.7399 - val_acc: 0.8317\n",
      "Epoch 17/75\n",
      "200/200 [==============================] - 221s - loss: 0.8269 - acc: 0.7913 - val_loss: 0.8340 - val_acc: 0.8150\n",
      "Epoch 18/75\n",
      "200/200 [==============================] - 220s - loss: 0.7961 - acc: 0.7939 - val_loss: 0.6910 - val_acc: 0.8317\n",
      "Epoch 19/75\n",
      "200/200 [==============================] - 220s - loss: 0.7765 - acc: 0.7945 - val_loss: 0.7689 - val_acc: 0.8350\n",
      "Epoch 20/75\n",
      "200/200 [==============================] - 221s - loss: 0.7289 - acc: 0.8117 - val_loss: 0.7434 - val_acc: 0.8383\n",
      "Epoch 21/75\n",
      "200/200 [==============================] - 220s - loss: 0.7356 - acc: 0.8107 - val_loss: 0.7206 - val_acc: 0.8492\n",
      "Epoch 22/75\n",
      "200/200 [==============================] - 221s - loss: 0.7145 - acc: 0.8165 - val_loss: 0.7840 - val_acc: 0.8350\n",
      "Epoch 23/75\n",
      "200/200 [==============================] - 221s - loss: 0.6836 - acc: 0.8228 - val_loss: 0.7171 - val_acc: 0.8433\n",
      "Epoch 24/75\n",
      "200/200 [==============================] - 221s - loss: 0.6750 - acc: 0.8243 - val_loss: 0.7168 - val_acc: 0.8433\n",
      "Epoch 25/75\n",
      "200/200 [==============================] - 220s - loss: 0.6485 - acc: 0.8332 - val_loss: 0.7051 - val_acc: 0.8433\n",
      "Epoch 26/75\n",
      "200/200 [==============================] - 221s - loss: 0.6372 - acc: 0.8415 - val_loss: 0.7619 - val_acc: 0.8342\n",
      "Epoch 27/75\n",
      "200/200 [==============================] - 220s - loss: 0.6077 - acc: 0.8459 - val_loss: 0.7687 - val_acc: 0.8358\n",
      "Epoch 28/75\n",
      "200/200 [==============================] - 220s - loss: 0.5954 - acc: 0.8482 - val_loss: 0.7092 - val_acc: 0.8450\n",
      "Epoch 29/75\n",
      "200/200 [==============================] - 222s - loss: 0.5863 - acc: 0.8499 - val_loss: 0.6947 - val_acc: 0.8492\n",
      "Epoch 30/75\n",
      "200/200 [==============================] - 220s - loss: 0.5675 - acc: 0.8553 - val_loss: 0.7020 - val_acc: 0.8567\n",
      "Epoch 31/75\n",
      "200/200 [==============================] - 222s - loss: 0.5521 - acc: 0.8602 - val_loss: 0.7699 - val_acc: 0.8308\n",
      "Epoch 32/75\n",
      "200/200 [==============================] - 220s - loss: 0.5521 - acc: 0.8595 - val_loss: 0.7096 - val_acc: 0.8542\n",
      "Epoch 33/75\n",
      "200/200 [==============================] - 221s - loss: 0.5273 - acc: 0.8650 - val_loss: 0.7306 - val_acc: 0.8458\n",
      "Epoch 34/75\n",
      "200/200 [==============================] - 221s - loss: 0.5126 - acc: 0.8729 - val_loss: 0.6702 - val_acc: 0.8517\n",
      "Epoch 35/75\n",
      "200/200 [==============================] - 221s - loss: 0.5090 - acc: 0.8727 - val_loss: 0.8106 - val_acc: 0.8408\n",
      "Epoch 36/75\n",
      "200/200 [==============================] - 220s - loss: 0.4894 - acc: 0.8793 - val_loss: 0.6667 - val_acc: 0.8533\n",
      "Epoch 37/75\n",
      "200/200 [==============================] - 221s - loss: 0.4712 - acc: 0.8818 - val_loss: 0.7181 - val_acc: 0.8492\n",
      "Epoch 38/75\n",
      "200/200 [==============================] - 220s - loss: 0.4675 - acc: 0.8861 - val_loss: 0.7169 - val_acc: 0.8550\n",
      "Epoch 39/75\n",
      "200/200 [==============================] - 221s - loss: 0.4600 - acc: 0.8885 - val_loss: 0.7419 - val_acc: 0.8558\n",
      "Epoch 40/75\n",
      "200/200 [==============================] - 220s - loss: 0.4522 - acc: 0.8884 - val_loss: 0.7108 - val_acc: 0.8508\n",
      "Epoch 41/75\n",
      "200/200 [==============================] - 221s - loss: 0.4355 - acc: 0.8929 - val_loss: 0.6953 - val_acc: 0.8542\n",
      "Epoch 42/75\n",
      "200/200 [==============================] - 221s - loss: 0.4179 - acc: 0.9008 - val_loss: 0.7565 - val_acc: 0.8467\n",
      "Epoch 43/75\n",
      "200/200 [==============================] - 220s - loss: 0.4112 - acc: 0.9008 - val_loss: 0.6255 - val_acc: 0.8642\n",
      "Epoch 44/75\n",
      "200/200 [==============================] - 220s - loss: 0.3960 - acc: 0.9072 - val_loss: 0.7725 - val_acc: 0.8408\n",
      "Epoch 45/75\n",
      "200/200 [==============================] - 221s - loss: 0.4003 - acc: 0.9013 - val_loss: 0.6995 - val_acc: 0.8617\n",
      "Epoch 46/75\n",
      "200/200 [==============================] - 219s - loss: 0.3867 - acc: 0.9087 - val_loss: 0.7061 - val_acc: 0.8517\n",
      "Epoch 47/75\n",
      "200/200 [==============================] - 220s - loss: 0.3690 - acc: 0.9148 - val_loss: 0.7232 - val_acc: 0.8558\n",
      "Epoch 48/75\n",
      "200/200 [==============================] - 221s - loss: 0.3687 - acc: 0.9119 - val_loss: 0.6910 - val_acc: 0.8692\n",
      "Epoch 49/75\n",
      "200/200 [==============================] - 221s - loss: 0.3553 - acc: 0.9185 - val_loss: 0.6717 - val_acc: 0.8558\n",
      "Epoch 50/75\n",
      "200/200 [==============================] - 221s - loss: 0.3621 - acc: 0.9169 - val_loss: 0.7320 - val_acc: 0.8608\n",
      "Epoch 51/75\n",
      "200/200 [==============================] - 221s - loss: 0.3460 - acc: 0.9188 - val_loss: 0.7335 - val_acc: 0.8575\n",
      "Epoch 52/75\n",
      "200/200 [==============================] - 220s - loss: 0.3291 - acc: 0.9254 - val_loss: 0.6761 - val_acc: 0.8583\n",
      "Epoch 53/75\n",
      "200/200 [==============================] - 220s - loss: 0.3325 - acc: 0.9233 - val_loss: 0.7113 - val_acc: 0.8542\n",
      "Epoch 54/75\n",
      "200/200 [==============================] - 145s - loss: 0.3185 - acc: 0.9286 - val_loss: 0.7203 - val_acc: 0.8525\n",
      "Epoch 55/75\n",
      "200/200 [==============================] - 140s - loss: 0.3183 - acc: 0.9295 - val_loss: 0.7144 - val_acc: 0.8675\n",
      "Epoch 56/75\n",
      "200/200 [==============================] - 141s - loss: 0.3111 - acc: 0.9304 - val_loss: 0.6576 - val_acc: 0.8508\n",
      "Epoch 57/75\n",
      "200/200 [==============================] - 141s - loss: 0.3003 - acc: 0.9344 - val_loss: 0.6891 - val_acc: 0.8600\n",
      "Epoch 58/75\n",
      "200/200 [==============================] - 141s - loss: 0.2957 - acc: 0.9345 - val_loss: 0.7483 - val_acc: 0.8583\n",
      "Epoch 59/75\n",
      "200/200 [==============================] - 140s - loss: 0.2977 - acc: 0.9341 - val_loss: 0.7747 - val_acc: 0.8533\n",
      "Epoch 60/75\n",
      "200/200 [==============================] - 140s - loss: 0.2804 - acc: 0.9391 - val_loss: 0.6579 - val_acc: 0.8750\n",
      "Epoch 61/75\n",
      "200/200 [==============================] - 141s - loss: 0.2790 - acc: 0.9405 - val_loss: 0.7285 - val_acc: 0.8650\n",
      "Epoch 62/75\n",
      "200/200 [==============================] - 140s - loss: 0.2737 - acc: 0.9436 - val_loss: 0.6641 - val_acc: 0.8583\n",
      "Epoch 63/75\n",
      "200/200 [==============================] - 141s - loss: 0.2746 - acc: 0.9402 - val_loss: 0.7040 - val_acc: 0.8683\n",
      "Epoch 64/75\n",
      "200/200 [==============================] - 139s - loss: 0.2610 - acc: 0.9460 - val_loss: 0.7080 - val_acc: 0.8658\n",
      "Epoch 65/75\n",
      "200/200 [==============================] - 141s - loss: 0.2520 - acc: 0.9483 - val_loss: 0.6815 - val_acc: 0.8625\n",
      "Epoch 66/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 140s - loss: 0.2506 - acc: 0.9470 - val_loss: 0.7070 - val_acc: 0.8708\n",
      "Epoch 67/75\n",
      "200/200 [==============================] - 141s - loss: 0.2462 - acc: 0.9482 - val_loss: 0.7383 - val_acc: 0.8533\n",
      "Epoch 68/75\n",
      "200/200 [==============================] - 141s - loss: 0.2407 - acc: 0.9489 - val_loss: 0.7168 - val_acc: 0.8642\n",
      "Epoch 69/75\n",
      "200/200 [==============================] - 140s - loss: 0.2433 - acc: 0.9490 - val_loss: 0.7197 - val_acc: 0.8558\n",
      "Epoch 70/75\n",
      "200/200 [==============================] - 141s - loss: 0.2267 - acc: 0.9523 - val_loss: 0.6873 - val_acc: 0.8675\n",
      "Epoch 71/75\n",
      "200/200 [==============================] - 141s - loss: 0.2370 - acc: 0.9488 - val_loss: 0.7126 - val_acc: 0.8642\n",
      "Epoch 72/75\n",
      "200/200 [==============================] - 141s - loss: 0.2370 - acc: 0.9492 - val_loss: 0.7247 - val_acc: 0.8742\n",
      "Epoch 73/75\n",
      "200/200 [==============================] - 141s - loss: 0.2213 - acc: 0.9559 - val_loss: 0.7170 - val_acc: 0.8683\n",
      "Epoch 74/75\n",
      "200/200 [==============================] - 140s - loss: 0.2235 - acc: 0.9546 - val_loss: 0.6658 - val_acc: 0.8750\n",
      "Epoch 75/75\n",
      "200/200 [==============================] - 140s - loss: 0.2158 - acc: 0.9551 - val_loss: 0.7461 - val_acc: 0.8642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5be6ed7e80>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "model.fit_generator(train_generator, steps_per_epoch=200,\n",
    "        epochs=75,validation_data=validation_generator,validation_steps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5:\n",
    "then extract test images and save the test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "img=cv2.imread(\"/home/sainathb/Image_Classification/sample_submission.csv.zip.jpg\")\n",
    "plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_img(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img,(224,224))\n",
    "    return img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "train=pd.read_csv(\"/home/sainathb/Image_Classification/sample_submission.csv\")\n",
    "trainimages=[]\n",
    "for img_path in tqdm(train['id'].values):\n",
    "        trainimages.append(read_img(\"/home/sainathb/Image_Classification/test/\"+ img_path+\".jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainimages=np.array(trainimages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k=model.predict(trainimages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('xception1.csv', k, delimiter=',') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
