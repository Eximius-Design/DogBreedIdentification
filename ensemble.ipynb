{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "set_session(tf.Session(config=config))\n",
    "#import keras\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from matplotlib.pyplot import imshow\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten,Activation, Conv2D, MaxPooling2D,BatchNormalization,GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"/home/sainathb/dog breed files/Image_Classification/labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ylabels=train['breed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10222, 120)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ylabels=np.array(pd.get_dummies(ylabels))\n",
    "ylabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "def read_img(img_path):\n",
    "    img = image.load_img(img_path,target_size=(400,400,3))\n",
    "    arr=image.img_to_array(img)\n",
    "    return arr/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_read_img(img_path):\n",
    "    img = image.load_img(img_path,target_size=(400,400,3))\n",
    "    arr=image.img_to_array(img)\n",
    "    return arr/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [01:04<00:00, 159.56it/s]\n"
     ]
    }
   ],
   "source": [
    "trainimages=[]\n",
    "for img_path in tqdm(train['id'].values):\n",
    "        trainimages.append(read_img(\"/home/sainathb/dog breed files/Image_Classification/train/\"+ img_path+\".jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainimages=np.array(trainimages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:51<00:00, 199.10it/s]\n"
     ]
    }
   ],
   "source": [
    "croptrainimages=[]\n",
    "for img_path in tqdm(train['id'].values):\n",
    "        croptrainimages.append(crop_read_img(\"/home/sainathb/dog breed files/Image_Classification/traincopy/train/\"+ img_path+\".jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "croptrainimages=np.array(croptrainimages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainimages,ylabels, test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=5)\n",
    "for train_index, test_index in sss.split(trainimages,ylabels):\n",
    "        X_train,X_test = trainimages[train_index], trainimages[test_index]\n",
    "        y_train, y_test = ylabels[train_index], ylabels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9199, 400, 400, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for train_index, test_index in sss.split(croptrainimages,ylabels):\n",
    "        cX_train,cX_test = croptrainimages[train_index], croptrainimages[test_index]\n",
    "        cy_train, cy_test = ylabels[train_index], ylabels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "base_model1= keras.applications.xception.Xception(include_top=False, weights='imagenet',input_shape=(400,400,3),pooling='avg')\n",
    "\n",
    "base_model2= keras.applications.inception_v3.InceptionV3(include_top=False, weights='imagenet',input_shape=(400,400,3),pooling='avg')\n",
    "\n",
    "base_model3 =InceptionResNetV2(include_top=False , weights='imagenet',input_shape=(400,400,3),pooling='avg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9199, 2048)\n",
      "(9199, 2048)\n",
      "(9199, 1536)\n"
     ]
    }
   ],
   "source": [
    "xpreds=base_model1.predict(x=X_train,batch_size=50)\n",
    "print(xpreds.shape)\n",
    "ipreds=base_model2.predict(x=X_train,batch_size=50)\n",
    "print(ipreds.shape)\n",
    "irpreds=base_model3.predict(x=X_train,batch_size=50)\n",
    "print(irpreds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9199, 5632)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain=np.concatenate([irpreds,ipreds,xpreds],axis=-1)\n",
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9199, 2048)\n",
      "(9199, 2048)\n",
      "(9199, 1536)\n"
     ]
    }
   ],
   "source": [
    "xfpreds=base_model1.predict(x=np.flip(X_train,axis=2),batch_size=10)\n",
    "print(xfpreds.shape)\n",
    "ifpreds=base_model2.predict(x=np.flip(X_train,axis=2),batch_size=10)\n",
    "print(ifpreds.shape)\n",
    "irfpreds=base_model3.predict(x=np.flip(X_train,axis=2),batch_size=10)\n",
    "print(irfpreds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9199, 5632)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xftrain=np.concatenate([irfpreds,ifpreds,xfpreds],axis=-1)\n",
    "Xftrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9199, 2048)\n",
      "(9199, 2048)\n",
      "(9199, 1536)\n"
     ]
    }
   ],
   "source": [
    "cxpreds=base_model1.predict(x=cX_train,batch_size=10)\n",
    "print(cxpreds.shape)\n",
    "cipreds=base_model2.predict(x=cX_train,batch_size=10)\n",
    "print(cipreds.shape)\n",
    "cirpreds=base_model3.predict(x=cX_train,batch_size=10)\n",
    "print(cirpreds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9199, 5632)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cXtrain=np.concatenate([cirpreds,cipreds,cxpreds],axis=-1)\n",
    "cXtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cxfpreds=base_model1.predict(x=np.flip(cX_train,axis=2),batch_size=100)\n",
    "print(cxfpreds.shape)\n",
    "cifpreds=base_model2.predict(x=np.flip(cX_train,axis=2),batch_size=100)\n",
    "print(cifpreds.shape)\n",
    "cirfpreds=base_model3.predict(x=np.flip(cX_train,axis=2),batch_size=100)\n",
    "print(cirfpreds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cXftrain=np.concatenate([cirfpreds,cifpreds,cxfpreds],axis=-1)\n",
    "cXftrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txpreds=base_model1.predict(x=X_test,batch_size=30)\n",
    "tipreds=base_model2.predict(x=X_test,batch_size=30)\n",
    "tirpreds=base_model3.predict(x=X_test,batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txfpreds=base_model1.predict(x=np.flip(X_test,axis=2),batch_size=50)\n",
    "tifpreds=base_model2.predict(x=np.flip(X_test,axis=2),batch_size=50)\n",
    "tirfpreds=base_model3.predict(x=np.flip(X_test,axis=2),batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023, 5632)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest=np.concatenate([tirpreds,tipreds,txpreds],axis=-1)\n",
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023, 5632)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xftest=np.concatenate([tirfpreds,tifpreds,txfpreds],axis=-1)\n",
    "Xftest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctxpreds=base_model1.predict(x=cX_test,batch_size=10)\n",
    "ctipreds=base_model2.predict(x=cX_test,batch_size=100)\n",
    "ctirpreds=base_model3.predict(x=cX_test,batch_size=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctxfpreds=base_model1.predict(x=np.flip(cX_test,axis=2),batch_size=50)\n",
    "ctifpreds=base_model2.predict(x=np.flip(cX_test,axis=2),batch_size=50)\n",
    "ctirfpreds=base_model3.predict(x=np.flip(cX_test,axis=2),batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023, 5632)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cXtest=np.concatenate([ctirpreds,ctipreds,ctxpreds],axis=-1)\n",
    "cXtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cXftest=np.concatenate([ctirfpreds,ctifpreds,ctxfpreds],axis=-1)\n",
    "cXftest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mymodel():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2048,input_shape=(5632,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(120))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks1=keras.callbacks.ModelCheckpoint('moda.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "callbacks2=keras.callbacks.ModelCheckpoint('modb.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "callbacks3=keras.callbacks.ModelCheckpoint('modc.h5', monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "callbacks4=keras.callbacks.ModelCheckpoint('modd.h5', monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor1=keras.callbacks.TensorBoard(log_dir='./logs/model1/', histogram_freq=0, batch_size=120, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "\n",
    "tensor2=keras.callbacks.TensorBoard(log_dir='./logs/model2', histogram_freq=0, batch_size=120, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9199 samples, validate on 1023 samples\n",
      "Epoch 1/120\n",
      "9199/9199 [==============================] - 2s 167us/step - loss: 1.1239 - acc: 0.7705 - val_loss: 0.2368 - val_acc: 0.9306\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/120\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.2163 - acc: 0.9311 - val_loss: 0.1740 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/120\n",
      "9199/9199 [==============================] - 1s 101us/step - loss: 0.1750 - acc: 0.9439 - val_loss: 0.1722 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1612 - acc: 0.9490 - val_loss: 0.1730 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1497 - acc: 0.9510 - val_loss: 0.1666 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1400 - acc: 0.9547 - val_loss: 0.1662 - val_acc: 0.9531\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/120\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.1319 - acc: 0.9593 - val_loss: 0.1648 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1284 - acc: 0.9597 - val_loss: 0.1641 - val_acc: 0.9541\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1263 - acc: 0.9597 - val_loss: 0.1614 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/120\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.1215 - acc: 0.9615 - val_loss: 0.1643 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1179 - acc: 0.9627 - val_loss: 0.1646 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.1165 - acc: 0.9639 - val_loss: 0.1592 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/120\n",
      "9199/9199 [==============================] - 1s 96us/step - loss: 0.1142 - acc: 0.9638 - val_loss: 0.1633 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/120\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.1129 - acc: 0.9662 - val_loss: 0.1617 - val_acc: 0.9531\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1124 - acc: 0.9639 - val_loss: 0.1619 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/120\n",
      "9199/9199 [==============================] - 1s 105us/step - loss: 0.1108 - acc: 0.9681 - val_loss: 0.1617 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/120\n",
      "9199/9199 [==============================] - 1s 103us/step - loss: 0.1099 - acc: 0.9659 - val_loss: 0.1600 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/120\n",
      "9199/9199 [==============================] - 1s 105us/step - loss: 0.1067 - acc: 0.9655 - val_loss: 0.1608 - val_acc: 0.9531\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/120\n",
      "9199/9199 [==============================] - 1s 105us/step - loss: 0.1027 - acc: 0.9689 - val_loss: 0.1607 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/120\n",
      "9199/9199 [==============================] - 1s 106us/step - loss: 0.1039 - acc: 0.9696 - val_loss: 0.1604 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/120\n",
      "9199/9199 [==============================] - 1s 104us/step - loss: 0.1043 - acc: 0.9677 - val_loss: 0.1615 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/120\n",
      "9199/9199 [==============================] - 1s 104us/step - loss: 0.1033 - acc: 0.9678 - val_loss: 0.1604 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/120\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.1039 - acc: 0.9699 - val_loss: 0.1600 - val_acc: 0.9531\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0999 - acc: 0.9685 - val_loss: 0.1593 - val_acc: 0.9531\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0999 - acc: 0.9697 - val_loss: 0.1610 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.1003 - acc: 0.9708 - val_loss: 0.1603 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0978 - acc: 0.9698 - val_loss: 0.1596 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0973 - acc: 0.9741 - val_loss: 0.1603 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/120\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0996 - acc: 0.9690 - val_loss: 0.1596 - val_acc: 0.9531\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0952 - acc: 0.9718 - val_loss: 0.1600 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/120\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0971 - acc: 0.9704 - val_loss: 0.1595 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/120\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0984 - acc: 0.9717 - val_loss: 0.1595 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0960 - acc: 0.9711 - val_loss: 0.1596 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0957 - acc: 0.9712 - val_loss: 0.1595 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0931 - acc: 0.9716 - val_loss: 0.1608 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0936 - acc: 0.9731 - val_loss: 0.1603 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/120\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0949 - acc: 0.9724 - val_loss: 0.1610 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0924 - acc: 0.9740 - val_loss: 0.1602 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0925 - acc: 0.9731 - val_loss: 0.1599 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0923 - acc: 0.9726 - val_loss: 0.1606 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0920 - acc: 0.9734 - val_loss: 0.1599 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0905 - acc: 0.9716 - val_loss: 0.1609 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 43/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0922 - acc: 0.9725 - val_loss: 0.1601 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 44/120\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0902 - acc: 0.9729 - val_loss: 0.1600 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0904 - acc: 0.9724 - val_loss: 0.1598 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00045: val_loss did not improve\n",
      "Epoch 46/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0909 - acc: 0.9723 - val_loss: 0.1608 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 47/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0894 - acc: 0.9745 - val_loss: 0.1604 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "Epoch 48/120\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0910 - acc: 0.9711 - val_loss: 0.1601 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "Epoch 49/120\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0897 - acc: 0.9724 - val_loss: 0.1605 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00049: val_loss did not improve\n",
      "Epoch 50/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0892 - acc: 0.9748 - val_loss: 0.1602 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00050: val_loss did not improve\n",
      "Epoch 51/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0892 - acc: 0.9731 - val_loss: 0.1603 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00051: val_loss did not improve\n",
      "Epoch 52/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0884 - acc: 0.9745 - val_loss: 0.1600 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00052: val_loss did not improve\n",
      "Epoch 53/120\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0874 - acc: 0.9749 - val_loss: 0.1592 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00053: val_loss did not improve\n",
      "Epoch 54/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0899 - acc: 0.9756 - val_loss: 0.1597 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00054: val_loss did not improve\n",
      "Epoch 55/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0867 - acc: 0.9735 - val_loss: 0.1600 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00055: val_loss did not improve\n",
      "Epoch 56/120\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0875 - acc: 0.9760 - val_loss: 0.1599 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00056: val_loss did not improve\n",
      "Epoch 57/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0853 - acc: 0.9760 - val_loss: 0.1600 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00057: val_loss did not improve\n",
      "Epoch 58/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0858 - acc: 0.9734 - val_loss: 0.1595 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00058: val_loss did not improve\n",
      "Epoch 59/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0868 - acc: 0.9749 - val_loss: 0.1597 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00059: val_loss did not improve\n",
      "Epoch 60/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0875 - acc: 0.9747 - val_loss: 0.1603 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00060: val_loss did not improve\n",
      "Epoch 61/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0866 - acc: 0.9753 - val_loss: 0.1597 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00061: val_loss did not improve\n",
      "Epoch 62/120\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0876 - acc: 0.9750 - val_loss: 0.1596 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00062: val_loss did not improve\n",
      "Epoch 63/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0865 - acc: 0.9753 - val_loss: 0.1596 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00063: val_loss did not improve\n",
      "Epoch 64/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0842 - acc: 0.9751 - val_loss: 0.1597 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00064: val_loss did not improve\n",
      "Epoch 65/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0850 - acc: 0.9752 - val_loss: 0.1600 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00065: val_loss did not improve\n",
      "Epoch 66/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0842 - acc: 0.9759 - val_loss: 0.1600 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00066: val_loss did not improve\n",
      "Epoch 67/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0858 - acc: 0.9771 - val_loss: 0.1599 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00067: val_loss did not improve\n",
      "Epoch 68/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0831 - acc: 0.9755 - val_loss: 0.1596 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00068: val_loss did not improve\n",
      "Epoch 69/120\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0825 - acc: 0.9768 - val_loss: 0.1598 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00069: val_loss did not improve\n",
      "Epoch 70/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0872 - acc: 0.9739 - val_loss: 0.1598 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00070: val_loss did not improve\n",
      "Epoch 71/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0821 - acc: 0.9770 - val_loss: 0.1596 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00071: val_loss did not improve\n",
      "Epoch 72/120\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0860 - acc: 0.9763 - val_loss: 0.1596 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00072: val_loss did not improve\n",
      "Epoch 73/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0841 - acc: 0.9768 - val_loss: 0.1592 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00073: val_loss did not improve\n",
      "Epoch 74/120\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0849 - acc: 0.9755 - val_loss: 0.1592 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00074: val_loss did not improve\n",
      "Epoch 75/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0823 - acc: 0.9758 - val_loss: 0.1591 - val_acc: 0.9531\n",
      "\n",
      "Epoch 00075: val_loss did not improve\n",
      "Epoch 76/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0824 - acc: 0.9752 - val_loss: 0.1591 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00076: val_loss did not improve\n",
      "Epoch 77/120\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0843 - acc: 0.9756 - val_loss: 0.1590 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00077: val_loss did not improve\n",
      "Epoch 78/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0833 - acc: 0.9756 - val_loss: 0.1588 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00078: val_loss did not improve\n",
      "Epoch 79/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0820 - acc: 0.9772 - val_loss: 0.1589 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00079: val_loss did not improve\n",
      "Epoch 80/120\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0838 - acc: 0.9758 - val_loss: 0.1592 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00080: val_loss did not improve\n",
      "Epoch 81/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0851 - acc: 0.9758 - val_loss: 0.1591 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00081: val_loss did not improve\n",
      "Epoch 82/120\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0806 - acc: 0.9779 - val_loss: 0.1591 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00082: val_loss did not improve\n",
      "Epoch 83/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0834 - acc: 0.9758 - val_loss: 0.1590 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00083: val_loss did not improve\n",
      "Epoch 84/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0845 - acc: 0.9741 - val_loss: 0.1591 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00084: val_loss did not improve\n",
      "Epoch 85/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0825 - acc: 0.9773 - val_loss: 0.1593 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00085: val_loss did not improve\n",
      "Epoch 86/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0824 - acc: 0.9784 - val_loss: 0.1597 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00086: val_loss did not improve\n",
      "Epoch 87/120\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0837 - acc: 0.9755 - val_loss: 0.1596 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00087: val_loss did not improve\n",
      "Epoch 88/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0802 - acc: 0.9774 - val_loss: 0.1601 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00088: val_loss did not improve\n",
      "Epoch 89/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0821 - acc: 0.9752 - val_loss: 0.1597 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00089: val_loss did not improve\n",
      "Epoch 90/120\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0809 - acc: 0.9767 - val_loss: 0.1599 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00090: val_loss did not improve\n",
      "Epoch 91/120\n",
      "9199/9199 [==============================] - 1s 96us/step - loss: 0.0814 - acc: 0.9765 - val_loss: 0.1601 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00091: val_loss did not improve\n",
      "Epoch 92/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0799 - acc: 0.9773 - val_loss: 0.1599 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00092: val_loss did not improve\n",
      "Epoch 93/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0794 - acc: 0.9787 - val_loss: 0.1597 - val_acc: 0.9501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00093: val_loss did not improve\n",
      "Epoch 94/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0801 - acc: 0.9775 - val_loss: 0.1600 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00094: val_loss did not improve\n",
      "Epoch 95/120\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0811 - acc: 0.9775 - val_loss: 0.1599 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00095: val_loss did not improve\n",
      "Epoch 96/120\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0804 - acc: 0.9771 - val_loss: 0.1597 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00096: val_loss did not improve\n",
      "Epoch 97/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0780 - acc: 0.9788 - val_loss: 0.1598 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00097: val_loss did not improve\n",
      "Epoch 98/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0817 - acc: 0.9752 - val_loss: 0.1597 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00098: val_loss did not improve\n",
      "Epoch 99/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0788 - acc: 0.9777 - val_loss: 0.1596 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00099: val_loss did not improve\n",
      "Epoch 100/120\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0808 - acc: 0.9759 - val_loss: 0.1598 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00100: val_loss did not improve\n",
      "Epoch 101/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0800 - acc: 0.9780 - val_loss: 0.1598 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00101: val_loss did not improve\n",
      "Epoch 102/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0800 - acc: 0.9781 - val_loss: 0.1597 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00102: val_loss did not improve\n",
      "Epoch 103/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0799 - acc: 0.9776 - val_loss: 0.1597 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00103: val_loss did not improve\n",
      "Epoch 104/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0816 - acc: 0.9778 - val_loss: 0.1597 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00104: val_loss did not improve\n",
      "Epoch 105/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0789 - acc: 0.9784 - val_loss: 0.1599 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00105: val_loss did not improve\n",
      "Epoch 106/120\n",
      "9199/9199 [==============================] - 1s 101us/step - loss: 0.0793 - acc: 0.9773 - val_loss: 0.1595 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00106: val_loss did not improve\n",
      "Epoch 107/120\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0809 - acc: 0.9760 - val_loss: 0.1596 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00107: val_loss did not improve\n",
      "Epoch 108/120\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0787 - acc: 0.9779 - val_loss: 0.1600 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00108: val_loss did not improve\n",
      "Epoch 109/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0785 - acc: 0.9778 - val_loss: 0.1599 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00109: val_loss did not improve\n",
      "Epoch 110/120\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0786 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00110: val_loss did not improve\n",
      "Epoch 111/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0763 - acc: 0.9796 - val_loss: 0.1598 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00111: val_loss did not improve\n",
      "Epoch 112/120\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0792 - acc: 0.9783 - val_loss: 0.1600 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00112: val_loss did not improve\n",
      "Epoch 113/120\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0789 - acc: 0.9753 - val_loss: 0.1600 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00113: val_loss did not improve\n",
      "Epoch 114/120\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0785 - acc: 0.9774 - val_loss: 0.1598 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00114: val_loss did not improve\n",
      "Epoch 115/120\n",
      "9199/9199 [==============================] - 1s 95us/step - loss: 0.0802 - acc: 0.9776 - val_loss: 0.1599 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00115: val_loss did not improve\n",
      "Epoch 116/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0775 - acc: 0.9783 - val_loss: 0.1600 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00116: val_loss did not improve\n",
      "Epoch 117/120\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0777 - acc: 0.9788 - val_loss: 0.1601 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00117: val_loss did not improve\n",
      "Epoch 118/120\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0751 - acc: 0.9792 - val_loss: 0.1598 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00118: val_loss did not improve\n",
      "Epoch 119/120\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0809 - acc: 0.9773 - val_loss: 0.1598 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00119: val_loss did not improve\n",
      "Epoch 120/120\n",
      "9199/9199 [==============================] - 1s 101us/step - loss: 0.0772 - acc: 0.9776 - val_loss: 0.1600 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00120: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8aeea71908>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1=mymodel()\n",
    "model1.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=0.085, decay=0.03, momentum=0.92, nesterov=True), metrics=['accuracy'])\n",
    "model1.fit(Xtrain,y_train, epochs=120,batch_size=120, shuffle=True,verbose=1,validation_data=(Xtest,y_test),callbacks=[callbacks1,tensor1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9199 samples, validate on 1023 samples\n",
      "Epoch 1/150\n",
      "9199/9199 [==============================] - 2s 167us/step - loss: 1.1236 - acc: 0.7638 - val_loss: 0.2310 - val_acc: 0.9267\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.2222 - acc: 0.9292 - val_loss: 0.1823 - val_acc: 0.9443\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1803 - acc: 0.9401 - val_loss: 0.1640 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.1598 - acc: 0.9495 - val_loss: 0.1656 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/150\n",
      "9199/9199 [==============================] - 1s 101us/step - loss: 0.1488 - acc: 0.9524 - val_loss: 0.1639 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/150\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.1375 - acc: 0.9575 - val_loss: 0.1624 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.1356 - acc: 0.9563 - val_loss: 0.1627 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.1283 - acc: 0.9600 - val_loss: 0.1589 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1267 - acc: 0.9610 - val_loss: 0.1619 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.1253 - acc: 0.9612 - val_loss: 0.1587 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1202 - acc: 0.9623 - val_loss: 0.1599 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.1198 - acc: 0.9610 - val_loss: 0.1605 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.1186 - acc: 0.9641 - val_loss: 0.1575 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1147 - acc: 0.9643 - val_loss: 0.1603 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1119 - acc: 0.9660 - val_loss: 0.1591 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.1149 - acc: 0.9647 - val_loss: 0.1575 - val_acc: 0.9531\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/150\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.1115 - acc: 0.9655 - val_loss: 0.1577 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1105 - acc: 0.9661 - val_loss: 0.1582 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.1077 - acc: 0.9680 - val_loss: 0.1584 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1073 - acc: 0.9664 - val_loss: 0.1590 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.1059 - acc: 0.9663 - val_loss: 0.1588 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1044 - acc: 0.9679 - val_loss: 0.1578 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/150\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.1033 - acc: 0.9680 - val_loss: 0.1575 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.1034 - acc: 0.9683 - val_loss: 0.1578 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/150\n",
      "9199/9199 [==============================] - 1s 101us/step - loss: 0.1023 - acc: 0.9689 - val_loss: 0.1582 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0996 - acc: 0.9700 - val_loss: 0.1579 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.1008 - acc: 0.9691 - val_loss: 0.1569 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0994 - acc: 0.9688 - val_loss: 0.1574 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/150\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0959 - acc: 0.9703 - val_loss: 0.1578 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1001 - acc: 0.9704 - val_loss: 0.1582 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0966 - acc: 0.9711 - val_loss: 0.1577 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0966 - acc: 0.9698 - val_loss: 0.1580 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1015 - acc: 0.9695 - val_loss: 0.1581 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0984 - acc: 0.9701 - val_loss: 0.1586 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0970 - acc: 0.9706 - val_loss: 0.1584 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0953 - acc: 0.9715 - val_loss: 0.1579 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0953 - acc: 0.9704 - val_loss: 0.1572 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0979 - acc: 0.9697 - val_loss: 0.1571 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0955 - acc: 0.9706 - val_loss: 0.1582 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0948 - acc: 0.9706 - val_loss: 0.1573 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0948 - acc: 0.9705 - val_loss: 0.1576 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0935 - acc: 0.9715 - val_loss: 0.1582 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 43/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0938 - acc: 0.9716 - val_loss: 0.1573 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 44/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0928 - acc: 0.9726 - val_loss: 0.1577 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/150\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0915 - acc: 0.9734 - val_loss: 0.1565 - val_acc: 0.9531\n",
      "\n",
      "Epoch 00045: val_loss did not improve\n",
      "Epoch 46/150\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0906 - acc: 0.9718 - val_loss: 0.1567 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 47/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0925 - acc: 0.9727 - val_loss: 0.1574 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "Epoch 48/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0888 - acc: 0.9723 - val_loss: 0.1573 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "Epoch 49/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0916 - acc: 0.9729 - val_loss: 0.1569 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00049: val_loss did not improve\n",
      "Epoch 50/150\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0925 - acc: 0.9743 - val_loss: 0.1569 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00050: val_loss did not improve\n",
      "Epoch 51/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0920 - acc: 0.9725 - val_loss: 0.1574 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00051: val_loss did not improve\n",
      "Epoch 52/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0898 - acc: 0.9737 - val_loss: 0.1572 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00052: val_loss did not improve\n",
      "Epoch 53/150\n",
      "9199/9199 [==============================] - 1s 101us/step - loss: 0.0914 - acc: 0.9735 - val_loss: 0.1571 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00053: val_loss did not improve\n",
      "Epoch 54/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0896 - acc: 0.9736 - val_loss: 0.1574 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00054: val_loss did not improve\n",
      "Epoch 55/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0902 - acc: 0.9721 - val_loss: 0.1573 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00055: val_loss did not improve\n",
      "Epoch 56/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0910 - acc: 0.9733 - val_loss: 0.1577 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00056: val_loss did not improve\n",
      "Epoch 57/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0891 - acc: 0.9742 - val_loss: 0.1577 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00057: val_loss did not improve\n",
      "Epoch 58/150\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0886 - acc: 0.9736 - val_loss: 0.1574 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00058: val_loss did not improve\n",
      "Epoch 59/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0897 - acc: 0.9727 - val_loss: 0.1575 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00059: val_loss did not improve\n",
      "Epoch 60/150\n",
      "9199/9199 [==============================] - 1s 96us/step - loss: 0.0887 - acc: 0.9742 - val_loss: 0.1578 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00060: val_loss did not improve\n",
      "Epoch 61/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0871 - acc: 0.9738 - val_loss: 0.1573 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00061: val_loss did not improve\n",
      "Epoch 62/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0843 - acc: 0.9754 - val_loss: 0.1572 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00062: val_loss did not improve\n",
      "Epoch 63/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0893 - acc: 0.9748 - val_loss: 0.1571 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00063: val_loss did not improve\n",
      "Epoch 64/150\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0915 - acc: 0.9723 - val_loss: 0.1573 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00064: val_loss did not improve\n",
      "Epoch 65/150\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0870 - acc: 0.9726 - val_loss: 0.1573 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00065: val_loss did not improve\n",
      "Epoch 66/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0886 - acc: 0.9735 - val_loss: 0.1572 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00066: val_loss did not improve\n",
      "Epoch 67/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0866 - acc: 0.9753 - val_loss: 0.1575 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00067: val_loss did not improve\n",
      "Epoch 68/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0865 - acc: 0.9743 - val_loss: 0.1580 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00068: val_loss did not improve\n",
      "Epoch 69/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0856 - acc: 0.9740 - val_loss: 0.1580 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00069: val_loss did not improve\n",
      "Epoch 70/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0849 - acc: 0.9755 - val_loss: 0.1581 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00070: val_loss did not improve\n",
      "Epoch 71/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0878 - acc: 0.9753 - val_loss: 0.1582 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00071: val_loss did not improve\n",
      "Epoch 72/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0863 - acc: 0.9749 - val_loss: 0.1581 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00072: val_loss did not improve\n",
      "Epoch 73/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0855 - acc: 0.9764 - val_loss: 0.1579 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00073: val_loss did not improve\n",
      "Epoch 74/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0884 - acc: 0.9728 - val_loss: 0.1579 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00074: val_loss did not improve\n",
      "Epoch 75/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0850 - acc: 0.9751 - val_loss: 0.1574 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00075: val_loss did not improve\n",
      "Epoch 76/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0847 - acc: 0.9765 - val_loss: 0.1574 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00076: val_loss did not improve\n",
      "Epoch 77/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0862 - acc: 0.9749 - val_loss: 0.1577 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00077: val_loss did not improve\n",
      "Epoch 78/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0870 - acc: 0.9742 - val_loss: 0.1580 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00078: val_loss did not improve\n",
      "Epoch 79/150\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0852 - acc: 0.9733 - val_loss: 0.1579 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00079: val_loss did not improve\n",
      "Epoch 80/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0852 - acc: 0.9743 - val_loss: 0.1577 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00080: val_loss did not improve\n",
      "Epoch 81/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0847 - acc: 0.9743 - val_loss: 0.1583 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00081: val_loss did not improve\n",
      "Epoch 82/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0851 - acc: 0.9755 - val_loss: 0.1581 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00082: val_loss did not improve\n",
      "Epoch 83/150\n",
      "9199/9199 [==============================] - 1s 102us/step - loss: 0.0862 - acc: 0.9742 - val_loss: 0.1580 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00083: val_loss did not improve\n",
      "Epoch 84/150\n",
      "9199/9199 [==============================] - 1s 101us/step - loss: 0.0828 - acc: 0.9763 - val_loss: 0.1578 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00084: val_loss did not improve\n",
      "Epoch 85/150\n",
      "9199/9199 [==============================] - 1s 107us/step - loss: 0.0837 - acc: 0.9763 - val_loss: 0.1574 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00085: val_loss did not improve\n",
      "Epoch 86/150\n",
      "9199/9199 [==============================] - 1s 106us/step - loss: 0.0851 - acc: 0.9748 - val_loss: 0.1575 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00086: val_loss did not improve\n",
      "Epoch 87/150\n",
      "9199/9199 [==============================] - 1s 106us/step - loss: 0.0824 - acc: 0.9760 - val_loss: 0.1577 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00087: val_loss did not improve\n",
      "Epoch 88/150\n",
      "9199/9199 [==============================] - 1s 106us/step - loss: 0.0834 - acc: 0.9758 - val_loss: 0.1579 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00088: val_loss did not improve\n",
      "Epoch 89/150\n",
      "9199/9199 [==============================] - 1s 108us/step - loss: 0.0810 - acc: 0.9771 - val_loss: 0.1575 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00089: val_loss did not improve\n",
      "Epoch 90/150\n",
      "9199/9199 [==============================] - 1s 108us/step - loss: 0.0818 - acc: 0.9768 - val_loss: 0.1578 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00090: val_loss did not improve\n",
      "Epoch 91/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0830 - acc: 0.9753 - val_loss: 0.1574 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00091: val_loss did not improve\n",
      "Epoch 92/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0838 - acc: 0.9751 - val_loss: 0.1573 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00092: val_loss did not improve\n",
      "Epoch 93/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0832 - acc: 0.9753 - val_loss: 0.1572 - val_acc: 0.9501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00093: val_loss did not improve\n",
      "Epoch 94/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0839 - acc: 0.9754 - val_loss: 0.1574 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00094: val_loss did not improve\n",
      "Epoch 95/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0837 - acc: 0.9748 - val_loss: 0.1576 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00095: val_loss did not improve\n",
      "Epoch 96/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0847 - acc: 0.9745 - val_loss: 0.1572 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00096: val_loss did not improve\n",
      "Epoch 97/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0841 - acc: 0.9756 - val_loss: 0.1577 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00097: val_loss did not improve\n",
      "Epoch 98/150\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0839 - acc: 0.9753 - val_loss: 0.1572 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00098: val_loss did not improve\n",
      "Epoch 99/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0841 - acc: 0.9768 - val_loss: 0.1576 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00099: val_loss did not improve\n",
      "Epoch 100/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0803 - acc: 0.9774 - val_loss: 0.1574 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00100: val_loss did not improve\n",
      "Epoch 101/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0816 - acc: 0.9767 - val_loss: 0.1575 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00101: val_loss did not improve\n",
      "Epoch 102/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0824 - acc: 0.9766 - val_loss: 0.1574 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00102: val_loss did not improve\n",
      "Epoch 103/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0816 - acc: 0.9751 - val_loss: 0.1577 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00103: val_loss did not improve\n",
      "Epoch 104/150\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0813 - acc: 0.9765 - val_loss: 0.1578 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00104: val_loss did not improve\n",
      "Epoch 105/150\n",
      "9199/9199 [==============================] - 1s 96us/step - loss: 0.0795 - acc: 0.9771 - val_loss: 0.1573 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00105: val_loss did not improve\n",
      "Epoch 106/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0814 - acc: 0.9774 - val_loss: 0.1575 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00106: val_loss did not improve\n",
      "Epoch 107/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0808 - acc: 0.9765 - val_loss: 0.1573 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00107: val_loss did not improve\n",
      "Epoch 108/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0824 - acc: 0.9763 - val_loss: 0.1574 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00108: val_loss did not improve\n",
      "Epoch 109/150\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0821 - acc: 0.9755 - val_loss: 0.1573 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00109: val_loss did not improve\n",
      "Epoch 110/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0795 - acc: 0.9766 - val_loss: 0.1573 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00110: val_loss did not improve\n",
      "Epoch 111/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0791 - acc: 0.9774 - val_loss: 0.1573 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00111: val_loss did not improve\n",
      "Epoch 112/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0797 - acc: 0.9756 - val_loss: 0.1573 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00112: val_loss did not improve\n",
      "Epoch 113/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0791 - acc: 0.9774 - val_loss: 0.1573 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00113: val_loss did not improve\n",
      "Epoch 114/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0816 - acc: 0.9772 - val_loss: 0.1573 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00114: val_loss did not improve\n",
      "Epoch 115/150\n",
      "9199/9199 [==============================] - 1s 101us/step - loss: 0.0812 - acc: 0.9774 - val_loss: 0.1572 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00115: val_loss did not improve\n",
      "Epoch 116/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0797 - acc: 0.9772 - val_loss: 0.1576 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00116: val_loss did not improve\n",
      "Epoch 117/150\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0796 - acc: 0.9781 - val_loss: 0.1573 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00117: val_loss did not improve\n",
      "Epoch 118/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0804 - acc: 0.9771 - val_loss: 0.1574 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00118: val_loss did not improve\n",
      "Epoch 119/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0778 - acc: 0.9788 - val_loss: 0.1573 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00119: val_loss did not improve\n",
      "Epoch 120/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0832 - acc: 0.9760 - val_loss: 0.1575 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00120: val_loss did not improve\n",
      "Epoch 121/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0792 - acc: 0.9776 - val_loss: 0.1576 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00121: val_loss did not improve\n",
      "Epoch 122/150\n",
      "9199/9199 [==============================] - 1s 101us/step - loss: 0.0812 - acc: 0.9758 - val_loss: 0.1576 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00122: val_loss did not improve\n",
      "Epoch 123/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0798 - acc: 0.9779 - val_loss: 0.1577 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00123: val_loss did not improve\n",
      "Epoch 124/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0788 - acc: 0.9766 - val_loss: 0.1576 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00124: val_loss did not improve\n",
      "Epoch 125/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0772 - acc: 0.9788 - val_loss: 0.1576 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00125: val_loss did not improve\n",
      "Epoch 126/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0788 - acc: 0.9780 - val_loss: 0.1577 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00126: val_loss did not improve\n",
      "Epoch 127/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0803 - acc: 0.9758 - val_loss: 0.1574 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00127: val_loss did not improve\n",
      "Epoch 128/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0780 - acc: 0.9785 - val_loss: 0.1573 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00128: val_loss did not improve\n",
      "Epoch 129/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0796 - acc: 0.9767 - val_loss: 0.1573 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00129: val_loss did not improve\n",
      "Epoch 130/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0790 - acc: 0.9778 - val_loss: 0.1574 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00130: val_loss did not improve\n",
      "Epoch 131/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0775 - acc: 0.9779 - val_loss: 0.1570 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00131: val_loss did not improve\n",
      "Epoch 132/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0781 - acc: 0.9773 - val_loss: 0.1571 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00132: val_loss did not improve\n",
      "Epoch 133/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0804 - acc: 0.9766 - val_loss: 0.1573 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00133: val_loss did not improve\n",
      "Epoch 134/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0795 - acc: 0.9771 - val_loss: 0.1573 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00134: val_loss did not improve\n",
      "Epoch 135/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0770 - acc: 0.9796 - val_loss: 0.1574 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00135: val_loss did not improve\n",
      "Epoch 136/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0810 - acc: 0.9776 - val_loss: 0.1574 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00136: val_loss did not improve\n",
      "Epoch 137/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0773 - acc: 0.9783 - val_loss: 0.1574 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00137: val_loss did not improve\n",
      "Epoch 138/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0800 - acc: 0.9773 - val_loss: 0.1575 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00138: val_loss did not improve\n",
      "Epoch 139/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0792 - acc: 0.9776 - val_loss: 0.1574 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00139: val_loss did not improve\n",
      "Epoch 140/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0770 - acc: 0.9778 - val_loss: 0.1575 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00140: val_loss did not improve\n",
      "Epoch 141/150\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0791 - acc: 0.9778 - val_loss: 0.1573 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00141: val_loss did not improve\n",
      "Epoch 142/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0775 - acc: 0.9778 - val_loss: 0.1576 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00142: val_loss did not improve\n",
      "Epoch 143/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0756 - acc: 0.9786 - val_loss: 0.1574 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00143: val_loss did not improve\n",
      "Epoch 144/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0770 - acc: 0.9777 - val_loss: 0.1574 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00144: val_loss did not improve\n",
      "Epoch 145/150\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.0768 - acc: 0.9776 - val_loss: 0.1576 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00145: val_loss did not improve\n",
      "Epoch 146/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0789 - acc: 0.9775 - val_loss: 0.1577 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00146: val_loss did not improve\n",
      "Epoch 147/150\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.0754 - acc: 0.9807 - val_loss: 0.1575 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00147: val_loss did not improve\n",
      "Epoch 148/150\n",
      "9199/9199 [==============================] - 1s 97us/step - loss: 0.0778 - acc: 0.9784 - val_loss: 0.1577 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00148: val_loss did not improve\n",
      "Epoch 149/150\n",
      "9199/9199 [==============================] - 1s 96us/step - loss: 0.0776 - acc: 0.9760 - val_loss: 0.1573 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00149: val_loss did not improve\n",
      "Epoch 150/150\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.0758 - acc: 0.9776 - val_loss: 0.1570 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00150: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8aeec67860>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=mymodel()\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=0.085, decay=0.03, momentum=0.92, nesterov=True), metrics=['accuracy'])\n",
    "model2.fit(Xftrain,y_train, epochs=150,batch_size=120, shuffle=True,verbose=1,validation_data=(Xftest,y_test),callbacks=[callbacks2,tensor2])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9199 samples, validate on 1023 samples\n",
      "Epoch 1/100\n",
      "9199/9199 [==============================] - 7s 747us/step - loss: 1.1974 - acc: 0.7445 - val_loss: 0.3321 - val_acc: 0.9042\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90420, saving model to modc.h5\n",
      "Epoch 2/100\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.3219 - acc: 0.9041 - val_loss: 0.2844 - val_acc: 0.9198\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90420 to 0.91984, saving model to modc.h5\n",
      "Epoch 3/100\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.2532 - acc: 0.9251 - val_loss: 0.2657 - val_acc: 0.9277\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91984 to 0.92766, saving model to modc.h5\n",
      "Epoch 4/100\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.2302 - acc: 0.9327 - val_loss: 0.2669 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00004: val_acc did not improve\n",
      "Epoch 5/100\n",
      "9199/9199 [==============================] - 1s 103us/step - loss: 0.2153 - acc: 0.9360 - val_loss: 0.2610 - val_acc: 0.9306\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.92766 to 0.93060, saving model to modc.h5\n",
      "Epoch 6/100\n",
      "9199/9199 [==============================] - 1s 109us/step - loss: 0.2036 - acc: 0.9387 - val_loss: 0.2553 - val_acc: 0.9316\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.93060 to 0.93157, saving model to modc.h5\n",
      "Epoch 7/100\n",
      "9199/9199 [==============================] - 1s 113us/step - loss: 0.1920 - acc: 0.9442 - val_loss: 0.2595 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00007: val_acc did not improve\n",
      "Epoch 8/100\n",
      "9199/9199 [==============================] - 1s 108us/step - loss: 0.1857 - acc: 0.9470 - val_loss: 0.2570 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00008: val_acc did not improve\n",
      "Epoch 9/100\n",
      "9199/9199 [==============================] - 1s 108us/step - loss: 0.1811 - acc: 0.9463 - val_loss: 0.2582 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00009: val_acc did not improve\n",
      "Epoch 10/100\n",
      "9199/9199 [==============================] - 1s 107us/step - loss: 0.1789 - acc: 0.9474 - val_loss: 0.2573 - val_acc: 0.9267\n",
      "\n",
      "Epoch 00010: val_acc did not improve\n",
      "Epoch 11/100\n",
      "9199/9199 [==============================] - 1s 103us/step - loss: 0.1730 - acc: 0.9515 - val_loss: 0.2611 - val_acc: 0.9306\n",
      "\n",
      "Epoch 00011: val_acc did not improve\n",
      "Epoch 12/100\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.1687 - acc: 0.9499 - val_loss: 0.2553 - val_acc: 0.9326\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.93157 to 0.93255, saving model to modc.h5\n",
      "Epoch 13/100\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.1630 - acc: 0.9521 - val_loss: 0.2562 - val_acc: 0.9316\n",
      "\n",
      "Epoch 00013: val_acc did not improve\n",
      "Epoch 14/100\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.1616 - acc: 0.9540 - val_loss: 0.2573 - val_acc: 0.9306\n",
      "\n",
      "Epoch 00014: val_acc did not improve\n",
      "Epoch 15/100\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1603 - acc: 0.9529 - val_loss: 0.2600 - val_acc: 0.9277\n",
      "\n",
      "Epoch 00015: val_acc did not improve\n",
      "Epoch 16/100\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.1586 - acc: 0.9546 - val_loss: 0.2574 - val_acc: 0.9306\n",
      "\n",
      "Epoch 00016: val_acc did not improve\n",
      "Epoch 17/100\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.1537 - acc: 0.9566 - val_loss: 0.2591 - val_acc: 0.9316\n",
      "\n",
      "Epoch 00017: val_acc did not improve\n",
      "Epoch 18/100\n",
      "9199/9199 [==============================] - 1s 96us/step - loss: 0.1520 - acc: 0.9537 - val_loss: 0.2582 - val_acc: 0.9326\n",
      "\n",
      "Epoch 00018: val_acc did not improve\n",
      "Epoch 19/100\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1524 - acc: 0.9573 - val_loss: 0.2574 - val_acc: 0.9306\n",
      "\n",
      "Epoch 00019: val_acc did not improve\n",
      "Epoch 20/100\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.1510 - acc: 0.9556 - val_loss: 0.2566 - val_acc: 0.9326\n",
      "\n",
      "Epoch 00020: val_acc did not improve\n",
      "Epoch 21/100\n",
      "9199/9199 [==============================] - 1s 100us/step - loss: 0.1521 - acc: 0.9541 - val_loss: 0.2578 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00021: val_acc did not improve\n",
      "Epoch 22/100\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.1484 - acc: 0.9585 - val_loss: 0.2585 - val_acc: 0.9306\n",
      "\n",
      "Epoch 00022: val_acc did not improve\n",
      "Epoch 23/100\n",
      "9199/9199 [==============================] - 1s 99us/step - loss: 0.1474 - acc: 0.9580 - val_loss: 0.2588 - val_acc: 0.9316\n",
      "\n",
      "Epoch 00023: val_acc did not improve\n",
      "Epoch 24/100\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1431 - acc: 0.9585 - val_loss: 0.2589 - val_acc: 0.9306\n",
      "\n",
      "Epoch 00024: val_acc did not improve\n",
      "Epoch 25/100\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1443 - acc: 0.9588 - val_loss: 0.2575 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00025: val_acc did not improve\n",
      "Epoch 26/100\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1418 - acc: 0.9583 - val_loss: 0.2587 - val_acc: 0.9316\n",
      "\n",
      "Epoch 00026: val_acc did not improve\n",
      "Epoch 27/100\n",
      "9199/9199 [==============================] - 1s 98us/step - loss: 0.1427 - acc: 0.9590 - val_loss: 0.2593 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00027: val_acc did not improve\n",
      "Epoch 28/100\n",
      " 120/9199 [..............................] - ETA: 0s - loss: 0.0950 - acc: 0.9750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-d14566d3429a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmymodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.085\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.92\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcXtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcy_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallbacks3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/work/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/work/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/work/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m         \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m   2475\u001b[0m                               **self.session_kwargs)\n",
      "\u001b[0;32m/work/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m                     \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model3=mymodel()\n",
    "model3.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=0.085, decay=0.03, momentum=0.92, nesterov=True), metrics=['accuracy'])\n",
    "model3.fit(cXtrain,cy_train, epochs=100,batch_size=120, shuffle=True,verbose=1,validation_data=(cXtest,cy_test),callbacks=[callbacks3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model4=mymodel()\n",
    "model4.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model4.fit(cXftrain,cy_train, epochs=100,batch_size=150, shuffle=True,verbose=1,validation_data=(cXftest,cy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10357/10357 [01:07<00:00, 153.01it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "test=pd.read_csv(\"/home/sainathb/dog breed files/Image_Classification/sample_submission.csv\")\n",
    "xtest=[]\n",
    "for img_path in tqdm(test['id'].values):\n",
    "        xtest.append(read_img(\"/home/sainathb/dog breed files/Image_Classification/test/\"+ img_path+\".jpg\"))\n",
    "xtest=np.array(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 7862/10357 [00:43<00:13, 178.91it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-7843f9ab834a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcxtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mcxtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_read_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/sainathb/dog breed files/Image_Classification/testcopy/\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcxtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcxtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-9bd060b12529>\u001b[0m in \u001b[0;36mcrop_read_img\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcrop_read_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0marr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/anaconda3/lib/python3.6/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, target_size, interpolation)\u001b[0m\n\u001b[1;32m    364\u001b[0m                         \", \".join(_PIL_INTERPOLATION_METHODS.keys())))\n\u001b[1;32m    365\u001b[0m             \u001b[0mresample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_PIL_INTERPOLATION_METHODS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth_height_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample)\u001b[0m\n\u001b[1;32m   1695\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown resampling filter\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1697\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                         \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cxtest=[]\n",
    "for img_path in tqdm(test['id'].values):\n",
    "        cxtest.append(crop_read_img(\"/home/sainathb/dog breed files/Image_Classification/testcopy/\"+ img_path+\".jpg\"))\n",
    "cxtest=np.array(cxtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 7862/10357 [01:00<00:19, 130.96it/s]"
     ]
    }
   ],
   "source": [
    "model1.load_weights('./moda.h5')\n",
    "model2.load_weights('./modb.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pxpreds=base_model1.predict(x=xtest,batch_size=10)\n",
    "pipreds=base_model2.predict(x=xtest,batch_size=10)\n",
    "pirpreds=base_model3.predict(x=xtest,batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10357, 5632)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pXtest=np.concatenate([pirpreds,pipreds,pxpreds],axis=-1)\n",
    "pXtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pxfpreds=base_model1.predict(x=np.flip(xtest,axis=2),batch_size=50)\n",
    "pifpreds=base_model2.predict(x=np.flip(xtest,axis=2),batch_size=50)\n",
    "pirfpreds=base_model3.predict(x=np.flip(xtest,axis=2),batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10357, 5632)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pXftest=np.concatenate([pirfpreds,pifpreds,pxfpreds],axis=-1)\n",
    "pXftest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cpxpreds=base_model1.predict(x=cxtest,batch_size=100)\n",
    "cpipreds=base_model2.predict(x=cxtest,batch_size=100)\n",
    "cpirpreds=base_model3.predict(x=cxtest,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cpXtest=np.concatenate([cpirpreds,cpipreds,cpxpreds],axis=-1)\n",
    "cpXtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cpxfpreds=base_model1.predict(x=np.flip(cxtest,axis=2),batch_size=50)\n",
    "cpifpreds=base_model2.predict(x=np.flip(cxtest,axis=2),batch_size=50)\n",
    "cpirfpreds=base_model3.predict(x=np.flip(cxtest,axis=2),batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cpXftest=np.concatenate([cpirfpreds,cpifpreds,cpxfpreds],axis=-1)\n",
    "cpXftest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.load_weights('model11.h5')\n",
    "model2.load_weights('model21.h5')\n",
    "model3.load_weights('model31.h5')\n",
    "model4.load_weights('model41.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=model1.predict(pXtest)\n",
    "b=model2.predict(pXftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e=(a+b)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10357, 120)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('zeropoint15.csv',e, delimiter=',',fmt=\"%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.save_weights('normal.h5')\n",
    "model2.save_weights('normalf.h5')\n",
    "model3.save_weights('normalc.h5')\n",
    "model4.save_weights('normalcf.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 10\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds=np.argmax(c,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=np.argmax(y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "breeds=np.unique(train['breed'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr=[]\n",
    "for i in preds:\n",
    "    pr.append(breeds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr1=[]\n",
    "for i in y:\n",
    "    pr1.append(breeds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm=confusion_matrix(pr1,pr,labels=breeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 18))\n",
    "_ = sns.heatmap(cm, ax=ax, yticklabels=breeds, xticklabels=breeds, robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr1=np.array(pr1)\n",
    "pr1.shape\n",
    "pr1=pr1.reshape(2045,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr=np.array(pr)\n",
    "pr=pr.reshape(2045,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.concatenate((pr1,pr),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"somefile.csv\",x,fmt=\"%s\",header=\"actual,pred,count\",delimiter=',',comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"somefile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "misclass_df = df[df['actual'] != df['pred']].groupby(['actual', 'pred']).sum().sort_values(['count'], ascending=False).reset_index()\n",
    "misclass_df['pair'] = misclass_df['actual'] + ' / ' + misclass_df['pred']\n",
    "misclass_df = misclass_df[['pair', 'count']].take(range(30))\n",
    "\n",
    "misclass_df.sort_values(['count']).plot.barh(figsize=(8, 10), x=misclass_df['pair'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('irix.csv', p, delimiter=',',fmt=\"%f\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "test=pd.read_csv(\"/home/sainathb/Image_Classification/sample_submission.csv\")\n",
    "xtest=[]\n",
    "for img_path in tqdm(test['id'].values):\n",
    "        xtest.append(read_img(\"/home/sainathb/Image_Classification/test/\"+ img_path+\".jpg\"))\n",
    "xtest=np.array(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model4=keras.applications.nasnet.NASNetLarge(input_shape=None, include_top=True, weights='imagenet', input_tensor=None, pooling=None, classes=1000)(include_top=False, weights='imagenet', input_tensor=None, input_shape=None, pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
